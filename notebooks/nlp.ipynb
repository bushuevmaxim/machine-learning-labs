{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ef56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb015807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мешок слов:\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2]\n",
      "\n",
      "Уникальные слова:\n",
      "['великолепный', 'сериал', 'который', 'поможет', 'успокоить', 'нервы', 'при', 'любых', 'стрессах', 'и', 'просто', 'скрасит', 'серые', 'будни', 'пожалуй', 'если', 'бы', 'я', 'посмотрел', 'только', 'первые', 'пару', 'сезонов', 'этого', 'сериала', 'с', 'легкой', 'руки', 'написал', 'ему', 'положительную', 'рецензию', 'в', 'общем', 'создатели', 'не', 'вернут', 'всё', 'на', 'круги', 'своя', 'то', 'рейтинги', 'следующих', 'будут', 'становится', 'все', 'ниже', 'а', 'зрительская', 'аудитория', 'будет', 'меньше']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "def create_bag_of_words(docs):\n",
    "    word_freq = {}\n",
    "    for doc in docs:\n",
    "        words = preprocess_text(doc)\n",
    "        for word in words:\n",
    "            if word not in word_freq:\n",
    "                word_freq[word] = 0\n",
    "            word_freq[word] += 1\n",
    "\n",
    "    unique_words = list(word_freq.keys())\n",
    "\n",
    "    bag_of_words = []\n",
    "    for doc in docs:\n",
    "        words = preprocess_text(doc)\n",
    "        vector = [0] * len(unique_words)\n",
    "        for i, word in enumerate(unique_words):\n",
    "            if word in words:\n",
    "                vector[i] = words.count(word)\n",
    "        bag_of_words.append(vector)\n",
    "\n",
    "    return bag_of_words, unique_words\n",
    "\n",
    "documents = [\"Великолепный сериал, который поможет успокоить нервы при любых стрессах и просто скрасит серые будни\",\n",
    "         \"Пожалуй, если бы я посмотрел только первые пару сезонов этого сериала, я бы с легкой руки написал ему положительную рецензию\",\n",
    "         \"В общем, если создатели этого сериала не вернут всё на круги своя, то рейтинги следующих сезонов будут становится все ниже и ниже, а зрительская аудитория будет все меньше и меньше.\"]\n",
    "\n",
    "\n",
    "\n",
    "bag_of_words, unique_words = create_bag_of_words(documents)\n",
    "\n",
    "print(\"Мешок слов:\")\n",
    "for vector in bag_of_words:\n",
    "    print(vector)\n",
    "\n",
    "print(\"\\nУникальные слова:\")\n",
    "print(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e20067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF for document 1:\n",
      "Великолепный: 0.12093908432571038\n",
      "сериал,: 0.12093908432571038\n",
      "который: 0.12093908432571038\n",
      "поможет: 0.12093908432571038\n",
      "успокоить: 0.12093908432571038\n",
      "нервы: 0.12093908432571038\n",
      "при: 0.12093908432571038\n",
      "любых: 0.12093908432571038\n",
      "стрессах: 0.12093908432571038\n",
      "и: 0.07142857142857142\n",
      "просто: 0.12093908432571038\n",
      "скрасит: 0.12093908432571038\n",
      "серые: 0.12093908432571038\n",
      "будни: 0.12093908432571038\n",
      "\n",
      "TF-IDF for document 2:\n",
      "Пожалуй,: 0.08465735902799727\n",
      "если: 0.06438410362258905\n",
      "бы: 0.1287682072451781\n",
      "я: 0.1287682072451781\n",
      "посмотрел: 0.08465735902799727\n",
      "только: 0.08465735902799727\n",
      "первые: 0.08465735902799727\n",
      "пару: 0.08465735902799727\n",
      "сезонов: 0.06438410362258905\n",
      "этого: 0.06438410362258905\n",
      "сериала,: 0.08465735902799727\n",
      "с: 0.05\n",
      "легкой: 0.08465735902799727\n",
      "руки: 0.08465735902799727\n",
      "написал: 0.08465735902799727\n",
      "ему: 0.08465735902799727\n",
      "положительную: 0.08465735902799727\n",
      "рецензию: 0.08465735902799727\n",
      "\n",
      "TF-IDF for document 3:\n",
      "В: 0.04292273574839269\n",
      "общем,: 0.05643823935199818\n",
      "если: 0.04292273574839269\n",
      "создатели: 0.05643823935199818\n",
      "этого: 0.04292273574839269\n",
      "сериала: 0.04292273574839269\n",
      "не: 0.04292273574839269\n",
      "вернут: 0.05643823935199818\n",
      "всё: 0.05643823935199818\n",
      "на: 0.04292273574839269\n",
      "круги: 0.05643823935199818\n",
      "своя,: 0.05643823935199818\n",
      "то: 0.03333333333333333\n",
      "рейтинги: 0.05643823935199818\n",
      "следующих: 0.05643823935199818\n",
      "сезонов: 0.04292273574839269\n",
      "будут: 0.05643823935199818\n",
      "становится: 0.05643823935199818\n",
      "все: 0.11287647870399636\n",
      "ниже: 0.05643823935199818\n",
      "и: 0.06666666666666667\n",
      "ниже,: 0.05643823935199818\n",
      "а: 0.03333333333333333\n",
      "зрительская: 0.05643823935199818\n",
      "аудитория: 0.05643823935199818\n",
      "будет: 0.05643823935199818\n",
      "меньше: 0.05643823935199818\n",
      "меньше.: 0.05643823935199818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_tf(term, document):\n",
    "    word_count = len(document.split())\n",
    "    term_count = document.split().count(term)\n",
    "    tf = term_count / word_count\n",
    "    return tf\n",
    "\n",
    "def calculate_idf(term, documents):\n",
    "    document_count = len(documents)\n",
    "    term_occurrences = sum(1 for document in documents if term in document)\n",
    "    idf = math.log((document_count + 1) / (1 + term_occurrences)) + 1\n",
    "    return idf\n",
    "\n",
    "def calculate_tfidf(term, document, documents):\n",
    "    tf = calculate_tf(term, document)\n",
    "    idf = calculate_idf(term, documents)\n",
    "    tfidf = tf * idf\n",
    "    return tfidf\n",
    "\n",
    "def calculate_tfidf_for_documents(documents):\n",
    "    tfidf_documents = []\n",
    "    for document in documents:\n",
    "        tfidf_document = {}\n",
    "        document_terms = document.split()\n",
    "        for term in document_terms:\n",
    "            tfidf_document[term] = calculate_tfidf(term, document, documents)\n",
    "        tfidf_documents.append(tfidf_document)\n",
    "    return tfidf_documents\n",
    "\n",
    "documents =[\"Великолепный сериал, который поможет успокоить нервы при любых стрессах и просто скрасит серые будни\",\n",
    "         \"Пожалуй, если бы я посмотрел только первые пару сезонов этого сериала, я бы с легкой руки написал ему положительную рецензию\",\n",
    "         \"В общем, если создатели этого сериала не вернут всё на круги своя, то рейтинги следующих сезонов будут становится все ниже и ниже, а зрительская аудитория будет все меньше и меньше.\"]\n",
    "\n",
    "tfidf_documents = calculate_tfidf_for_documents(documents)\n",
    "for i, document in enumerate(tfidf_documents):\n",
    "    print(f\"TF-IDF for document {i+1}:\")\n",
    "    for term, tfidf in document.items():\n",
    "        print(f\"{term}: {tfidf}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9250cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.120939</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.112876</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.056438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \n",
       "0  0.120939  0.120939  0.120939  0.120939  0.120939  0.120939  0.120939  \\\n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         7         8         9   ...        46        47        48        49   \n",
       "0  0.120939  0.120939  0.066667  ...  0.000000  0.000000  0.000000  0.000000  \\\n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.066667  ...  0.056438  0.112876  0.056438  0.056438   \n",
       "\n",
       "         50        51        52        53        54        55  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.033333  0.056438  0.056438  0.056438  0.056438  0.056438  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_matrix(document):\n",
    "    matrix = []\n",
    "    result = {}\n",
    "    for d in document:\n",
    "        result.update(d)\n",
    "    unique_words = list(result.keys())\n",
    "    for words in document:\n",
    "        vector = [0] * len(unique_words)\n",
    "        for i, word in enumerate(unique_words):\n",
    "            if word in words:\n",
    "                vector[i] = result[word]\n",
    "        matrix.append(vector)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "f = get_matrix(tfidf_documents)\n",
    "data = pd.DataFrame(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83283899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF for document 1:\n",
      "Go: 0.22361985965358788\n",
      "until: 0.31649259607826036\n",
      "jurong: 0.4466270803504795\n",
      "point,: 0.4466270803504795\n",
      "crazy..: 0.4466270803504795\n",
      "Available: 0.41196972132248233\n",
      "only: 0.22247695274978538\n",
      "in: 0.07827322735642894\n",
      "bugis: 0.38398893192571115\n",
      "n: 0.05569551144273989\n",
      "great: 0.25856707456580147\n",
      "world: 0.31467421386971667\n",
      "la: 0.13288897928838259\n",
      "e: 0.05328138479630617\n",
      "buffet...: 0.4466270803504795\n",
      "Cine: 0.4466270803504795\n",
      "there: 0.21999710569281677\n",
      "got: 0.20363646013239595\n",
      "amore: 0.4466270803504795\n",
      "wat...: 0.3570391068890768\n",
      "\n",
      "TF-IDF for document 2:\n",
      "Ok: 0.7342221604152019\n",
      "lar...: 1.1225528382788952\n",
      "Joking: 1.4887569345015983\n",
      "wif: 0.9936878569066483\n",
      "u: 0.20750047346799366\n",
      "oni...: 1.421179416483571\n",
      "\n",
      "TF-IDF for document 3:\n",
      "Free: 0.1963769429473016\n",
      "entry: 0.46358532654574186\n",
      "in: 0.055909448111734955\n",
      "2: 0.10183803218614007\n",
      "a: 0.039071469642958795\n",
      "wkly: 0.25813548267039876\n",
      "comp: 0.18189604622915287\n",
      "to: 0.20465563425528513\n",
      "win: 0.1710502457363592\n",
      "FA: 0.4700833107032938\n",
      "Cup: 0.28629467411197984\n",
      "final: 0.22606614005590023\n",
      "tkts: 0.28629467411197984\n",
      "21st: 0.2942640866589159\n",
      "May: 0.21783315224833483\n",
      "2005.: 0.2942640866589159\n",
      "Text: 0.20551742059505876\n",
      "87121: 0.26530229322261845\n",
      "receive: 0.21293311219428177\n",
      "question(std: 0.30453844638933664\n",
      "txt: 0.17369695902756357\n",
      "rate)T&C's: 0.30453844638933664\n",
      "apply: 0.2167978830742901\n",
      "08452810075over18's: 0.30453844638933664\n",
      "\n",
      "TF-IDF for document 4:\n",
      "U: 0.5672554049893288\n",
      "dun: 0.5043773948785288\n",
      "say: 0.4332614893825331\n",
      "so: 0.2514612621741213\n",
      "early: 0.5420115583127173\n",
      "hor...: 0.7751887726274024\n",
      "c: 0.13286028502760994\n",
      "already: 0.4690709699013593\n",
      "then: 0.40399138520704103\n",
      "say...: 0.7490358569499679\n",
      "\n",
      "TF-IDF for document 5:\n",
      "Nah: 0.5559841165208589\n",
      "I: 0.15004668691178483\n",
      "don't: 0.38853675454355024\n",
      "think: 0.35198713694769224\n",
      "he: 0.28390549225556355\n",
      "goes: 0.48981478842677345\n",
      "to: 0.14693225023456372\n",
      "usf,: 0.6559289614539558\n",
      "lives: 0.6166346827027258\n",
      "around: 0.4280958290017782\n",
      "here: 0.27239918265341273\n",
      "though: 0.4136302727323214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/spam.csv', encoding='latin-1')\n",
    "y = df[\"v1\"]\n",
    "X = list(df[\"v2\"])\n",
    "\n",
    "tfidf_documents = calculate_tfidf_for_documents(X)\n",
    "for i, document in enumerate(tfidf_documents):\n",
    "    if(i == 5):\n",
    "        break\n",
    "    print(f\"TF-IDF for document {i+1}:\")\n",
    "    for term, tfidf in document.items():\n",
    "        print(f\"{term}: {tfidf}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a73a0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15575</th>\n",
       "      <th>15576</th>\n",
       "      <th>15577</th>\n",
       "      <th>15578</th>\n",
       "      <th>15579</th>\n",
       "      <th>15580</th>\n",
       "      <th>15581</th>\n",
       "      <th>15582</th>\n",
       "      <th>15583</th>\n",
       "      <th>15584</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.319457</td>\n",
       "      <td>0.210995</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.374518</td>\n",
       "      <td>0.222477</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>0.187312</td>\n",
       "      <td>0.111391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297751</td>\n",
       "      <td>0.297751</td>\n",
       "      <td>0.297751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.029924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.893254</td>\n",
       "      <td>0.893254</td>\n",
       "      <td>0.893254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343559</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.488757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 15585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6       \n",
       "0     0.319457  0.210995  0.446627  0.446627  0.446627  0.374518  0.222477  \\\n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5567  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5568  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5569  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5570  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5571  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9      ...  15575     15576     15577     15578   \n",
       "0     0.06021  0.187312  0.111391  ...    0.0  0.000000  0.000000  0.000000  \\\n",
       "1     0.00000  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "2     0.06021  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "3     0.00000  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "4     0.00000  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "...       ...       ...       ...  ...    ...       ...       ...       ...   \n",
       "5567  0.00000  0.000000  0.000000  ...    0.0  0.297751  0.297751  0.297751   \n",
       "5568  0.00000  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "5569  0.06021  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "5570  0.06021  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "5571  0.00000  0.000000  0.000000  ...    0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "         15579     15580     15581     15582     15583     15584  \n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "5567  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5568  1.029924  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5569  0.000000  0.893254  0.893254  0.893254  0.000000  0.000000  \n",
       "5570  0.000000  0.000000  0.000000  0.000000  0.343559  0.000000  \n",
       "5571  0.000000  0.000000  0.000000  0.000000  0.000000  1.488757  \n",
       "\n",
       "[5572 rows x 15585 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matr = get_matrix(tfidf_documents)\n",
    "data = pd.DataFrame(matr)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c441c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5567    0\n",
       "5568    1\n",
       "5569    1\n",
       "5570    1\n",
       "5571    1\n",
       "Name: v1, Length: 5572, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maping = {\n",
    "    \"ham\" : 1,\n",
    "    \"spam\": 0\n",
    "}\n",
    "\n",
    "y = y.replace(maping)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d83abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsClassification:\n",
    "    @staticmethod\n",
    "    def accuracy(y_test, y_pred):\n",
    "        y_true, predictions = np.array(y_test), np.array(y_pred)\n",
    "        return len([x for x, y  in zip(y_true, predictions) if x  == y])/len(y_true)\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_test, y_pred):\n",
    "        y_true, predictions = np.array(y_test), np.array(y_pred)\n",
    "        TP = FP =TN =FN = 0\n",
    "        for test, pred in zip(y_true, predictions):\n",
    "            if (test == 1 and pred == 1):\n",
    "                TP += 1 \n",
    "            elif (test == 0 and pred == 0):\n",
    "                TN += 1\n",
    "            elif (test == 1 and pred == 0):\n",
    "                FN += 1\n",
    "            elif (test == 0 and pred == 1):\n",
    "                FP += 1\n",
    "        return [[TP, FP],[FN, TN]]\n",
    "    @staticmethod\n",
    "    def precision( y_test, y_pred):\n",
    "        matrix = MetricsClassification.confusion_matrix(y_test, y_pred)\n",
    "        TP = matrix[0][0]\n",
    "        FP = matrix[0][1]\n",
    "        return TP/(TP + FP)\n",
    "    @staticmethod\n",
    "    def recall(y_test, y_pred):\n",
    "        matrix = MetricsClassification.confusion_matrix(y_test, y_pred)\n",
    "        TP = matrix[0][0]\n",
    "        FN = matrix[1][0]\n",
    "        return TP/(TP + FN)\n",
    "    \n",
    "    @staticmethod\n",
    "    def f_score(y_test, y_pred):\n",
    "        recall_score = MetricsClassification.recall(y_test, y_pred)\n",
    "        precision_score = MetricsClassification.precision(y_test, y_pred)\n",
    "        return 2*(recall_score * precision_score)/ (recall_score+precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "069c3724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X, num_components):\n",
    "    X_meaned = X - np.mean(X, axis=0)\n",
    "    cov_matrix = np.cov(X_meaned, rowvar=False)\n",
    "    eigen_values, eigen_vectors = np.linalg.eigh(cov_matrix)\n",
    "    sorted_index = np.argsort(eigen_values)[::-1]\n",
    "    sorted_eigenvalues = eigen_values[sorted_index]\n",
    "    sorted_eigenvectors = eigen_vectors[:, sorted_index]\n",
    "    eigenvector_subset = sorted_eigenvectors[:, 0:num_components]\n",
    "    X_reduced = np.dot(eigenvector_subset.transpose(), X_meaned.transpose()).transpose()\n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e77305cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pca(data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a81716ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9330143540669856\n",
      "[[690, 42], [14, 90]]\n",
      "0.9426229508196722\n",
      "0.9801136363636364\n",
      "0.9610027855153203\n"
     ]
    }
   ],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = np.sqrt(np.sum((self.X_train - x) ** 2, axis=1))\n",
    "            indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = np.array(self.y_train)[indices]\n",
    "            most_common_label = np.bincount(k_nearest_labels).argmax()\n",
    "            predictions.append(most_common_label)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=4)\n",
    "knn = KNN(10)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(MetricsClassification.accuracy(y_test, predictions))\n",
    "print(MetricsClassification.confusion_matrix(y_test, predictions))\n",
    "print(MetricsClassification.precision(y_test, predictions))\n",
    "print(MetricsClassification.recall(y_test, predictions))\n",
    "print(MetricsClassification.f_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d61d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76       132\n",
      "           1       0.94      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.93       836\n",
      "   macro avg       0.90      0.83      0.86       836\n",
      "weighted avg       0.93      0.93      0.93       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "489b3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af225e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32352823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spam.csv', encoding='latin-1')\n",
    "y = df[\"v1\"]\n",
    "X = df[\"v2\"]\n",
    "data_samples = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76716b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56576cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=20, \n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1264d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "just ask hey meet min house live end month ah\n",
      "Topic #1:\n",
      "prize claim won number cash urgent win txt guaranteed cool\n",
      "Topic #2:\n",
      "ok good did way doing night today oh home just\n",
      "Topic #3:\n",
      "come ur da ì_ send msg service customer care soon\n",
      "Topic #4:\n",
      "day going great said went happy wish hope man lunch\n",
      "Topic #5:\n",
      "gt lt know don time want just need think dont\n",
      "Topic #6:\n",
      "lor got like wat say pls lol buy cos dun\n",
      "Topic #7:\n",
      "free stop reply text txt new www mobile com week\n",
      "Topic #8:\n",
      "sorry later love ll dear amp ur life thanks gud\n",
      "Topic #9:\n",
      "hi home im babe love phone miss tell mobile text\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda, tf_vectorizer.get_feature_names_out(), 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
